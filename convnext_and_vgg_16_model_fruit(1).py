# -*- coding: utf-8 -*-
"""convnext-and-vgg-16-model-fruit(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fT57do4xCwOBjfTWefZH9a8FSYyv-b62

# '''FruitVision Transfer Learning Implementation'''

Import Libraries
"""

# Core Libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torch.backends.cudnn as cudnn
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms, models
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from torch.cuda.amp import GradScaler, autocast

# Analytics & Visualization
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.metrics import classification_report, confusion_matrix
import random
import pickle
import warnings
warnings.filterwarnings('ignore')

"""# GPU SETUP AND VERIFICATION"""

def setup_gpu():
    if torch.cuda.is_available():
        device_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        device_name = torch.cuda.get_device_name(current_device)
        gpu_memory = torch.cuda.get_device_properties(current_device).total_memory / 1e9

        print("="*60)
        print("TRANSFER LEARNING 2 - GPU CONFIGURATION")
        print("="*60)
        print(f"✅ CUDA Available: {torch.cuda.is_available()}")
        print(f"✅ PyTorch Version: {torch.__version__}")
        print(f"✅ GPU Count: {device_count}")
        print(f"✅ Current GPU: {current_device}")
        print(f"✅ GPU Name: {device_name}")
        print(f"✅ GPU Memory: {gpu_memory:.2f} GB")

        cudnn.benchmark = True
        cudnn.deterministic = True
        return f'cuda:{current_device}'
    else:
        print("❌ CUDA not available!")
        return 'cpu'

DEVICE = setup_gpu()
print("="*60)

"""# CONFIGURATION"""

# Reproducibility
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)

# Paths and hyperparameters
DATA_DIR = '/kaggle/input/fruitvision-a-benchmark-dataset-for-fresh/Fruits Original'
BATCH_SIZE = 24
IMG_SIZE = (224, 224)
LEARNING_RATE = 0.0001
EPOCHS = 20
print(f"✅ Configuration: Batch={BATCH_SIZE}, Epochs={EPOCHS}, LR={LEARNING_RATE}")

# GPU Memory Management
def clear_gpu_memory():
    if DEVICE.startswith('cuda'):
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats(DEVICE)

def print_gpu_memory():
    if DEVICE.startswith('cuda'):
        allocated = torch.cuda.memory_allocated(DEVICE) / 1e9
        cached = torch.cuda.memory_reserved(DEVICE) / 1e9
        max_alloc = torch.cuda.max_memory_allocated(DEVICE) / 1e9
        print(f"GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB, Max: {max_alloc:.2f}GB")

"""
 # DATA TRANSFORMS AND LOADERS
"""

# Data augmentation transforms
train_transforms = transforms.Compose([
    transforms.TrivialAugmentWide(),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=10),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),
    transforms.Resize(IMG_SIZE),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_test_transforms = transforms.Compose([
    transforms.Resize(IMG_SIZE),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def create_dataloaders(dataset_path, batch_size=24):
    """Create optimized dataloaders with GPU pinning"""
    full_dataset = datasets.ImageFolder(dataset_path)

    # Dataset splitting
    total_size = len(full_dataset)
    train_size = int(0.7 * total_size)
    val_size = int(0.15 * total_size)
    test_size = total_size - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(
        full_dataset, [train_size, val_size, test_size])

    # Apply transforms
    train_dataset.dataset.transform = train_transforms
    val_dataset.dataset.transform = val_test_transforms
    test_dataset.dataset.transform = val_test_transforms

    # Create dataloaders
    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True,
        num_workers=4, pin_memory=True, persistent_workers=True
    )
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False,
        num_workers=4, pin_memory=True, persistent_workers=True
    )
    test_loader = DataLoader(
        test_dataset, batch_size=batch_size, shuffle=False,
        num_workers=4, pin_memory=True, persistent_workers=True
    )

    return train_loader, val_loader, test_loader, train_size, val_size, test_size, full_dataset.classes

"""MODEL CREATION

    '''Create transfer learning model with custom classifier'''
"""

def create_transfer_model(model_name, num_classes, freeze_backbone=True):

    print(f"\n--- Creating {model_name} ---")

    # VGG16 Model
    if model_name == "vgg16":
        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
        if freeze_backbone:
            for param in model.features.parameters():
                param.requires_grad = False
            print("✅ Backbone frozen")

        # Custom classifier
        model.classifier = nn.Sequential(
            nn.Linear(25088, 4096),
            nn.ReLU(True),
            nn.Dropout(0.5),
            nn.Linear(4096, 1024),
            nn.ReLU(True),
            nn.Dropout(0.5),
            nn.Linear(1024, 512),
            nn.ReLU(True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes))

    # ConvNeXt-Tiny Model
    elif model_name == "convnext_tiny":
        model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)
        if freeze_backbone:
            for param in model.features.parameters():
                param.requires_grad = False
            print("✅ Backbone frozen")

        # Custom classifier
        model.classifier = nn.Sequential(
            nn.Flatten(1),
            nn.LayerNorm((768,), eps=1e-06, elementwise_affine=True),
            nn.Dropout(0.2),
            nn.Linear(768, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes))

    else:
        raise ValueError(f"Model {model_name} not supported")

    # Parameter count
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"✅ Total params: {total_params:,}")
    print(f"✅ Trainable params: {trainable_params:,}")

    return model.to(DEVICE)

"""TRAINING FUNCTION"""

def train_transfer_model(model, model_name, train_loader, val_loader, epochs, lr, device, task_type):

    print(f"\n--- Training {model_name} for {task_type} ---")

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),
                           lr=lr, weight_decay=1e-4)
    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, eta_min=1e-7)
    scaler = GradScaler()

    # Early stopping setup
    early_stopping_patience = 7
    min_val_loss = float('inf')
    epochs_no_improve = 0
    best_model_state = None

    # Training history
    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}
    clear_gpu_memory()

    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss, train_correct, train_total = 0, 0, 0

        for batch_idx, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            optimizer.zero_grad()

            # Mixed precision training
            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            # Metrics calculation
            train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

            # Memory management
            if batch_idx % 50 == 0:
                torch.cuda.empty_cache()

        # Validation phase
        model.eval()
        val_loss, val_correct, val_total = 0, 0, 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)

                with autocast():
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)

                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        # Calculate epoch metrics
        avg_train_loss = train_loss / train_total
        avg_val_loss = val_loss / val_total
        avg_train_acc = train_correct / train_total
        avg_val_acc = val_correct / val_total

        # Update history
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        history['train_acc'].append(avg_train_acc)
        history['val_acc'].append(avg_val_acc)

        # Print progress
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Epoch {epoch+1}/{epochs} | Train Acc: {avg_train_acc:.4f} | Val Acc: {avg_val_acc:.4f} | "
              f"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | LR: {current_lr:.6f}")

        scheduler.step()

        # Early stopping check
        if avg_val_loss < min_val_loss:
            min_val_loss = avg_val_loss
            epochs_no_improve = 0
            best_model_state = model.state_dict().copy()
            torch.save(model.state_dict(), f'{model_name}_{task_type.lower().replace(" ", "_")}_best.pth')
        else:
            epochs_no_improve += 1
            if epochs_no_improve >= early_stopping_patience:
                print(f"Early stopping at epoch {epoch+1}")
                break

        # Memory monitoring
        if epoch % 5 == 0:
            print_gpu_memory()

    # Load best model weights
    if best_model_state is not None:
        model.load_state_dict(best_model_state)

    clear_gpu_memory()
    return history

"""EVALUATION FUNCTION"""

def evaluate_transfer_model(model, model_name, test_loader, class_names, device, task_type):
    """Evaluate model and generate classification report"""
    print(f"\n--- Evaluating {model_name} for {task_type} ---")
    model.eval()
    y_pred, y_true = [], []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device, non_blocking=True)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            y_pred.extend(predicted.cpu().numpy())
            y_true.extend(labels.cpu().numpy())

    # Generate classification report
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0)
    accuracy = report['accuracy']
    f1_macro = report['macro avg']['f1-score']

    print(f"✅ Test Accuracy: {accuracy:.4f}")
    print(f"✅ F1-Macro Score: {f1_macro:.4f}")

    # Detailed report
    print("\nDetailed Classification Report:")
    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix: {model_name} ({task_type})', fontsize=14)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    return {'accuracy': accuracy, 'f1_macro': f1_macro}

"""MAIN EXECUTION"""

# ======================
if __name__ == "__main__":

    print("\n" + "="*60)
    print("Fruit Vision")
    print("="*60)

    # Create dataloaders
    train_loader, val_loader, test_loader, train_size, val_size, test_size, class_names = create_dataloaders(DATA_DIR, BATCH_SIZE)
    NUM_CLASSES = len(class_names)
    print(f"Variety Classes ({NUM_CLASSES}): {class_names}")
    print(f"Dataset sizes: Train={train_size}, Val={val_size}, Test={test_size}")

    # VGG16 Training
    print("\n" + "="*40)
    print("VGG16 - VARIETY CLASSIFICATION")
    print("="*40)
    vgg_model = create_transfer_model("vgg16", NUM_CLASSES)
    vgg_history = train_transfer_model(
        vgg_model, "VGG16", train_loader, val_loader,
        EPOCHS, LEARNING_RATE, DEVICE, "Variety Classification"
    )

    # Plot training history
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 2, 1)
    plt.plot(vgg_history['train_acc'], label='Train', marker='o')
    plt.plot(vgg_history['val_acc'], label='Validation', marker='s')
    plt.title('VGG16 - Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(alpha=0.3)

    plt.subplot(1, 2, 2)
    plt.plot(vgg_history['train_loss'], label='Train', marker='o')
    plt.plot(vgg_history['val_loss'], label='Validation', marker='s')
    plt.title('VGG16 - Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # VGG16 Evaluation
    vgg_results = evaluate_transfer_model(
        vgg_model, "VGG16", test_loader, class_names, DEVICE, "Variety Classification"
    )

    # Save model info
    model_info = {
        'model': 'VGG16',
        'classes': class_names,
        'accuracy': vgg_results['accuracy'],
        'f1_score': vgg_results['f1_macro']
    }
    with open('vgg16_model.pkl', 'wb') as f:
        pickle.dump(model_info, f)

"""# ConvNeXt-Tiny Training"""

# ConvNeXt-Tiny Training
    print("\n" + "="*40)
    print("CONVNEXT-TINY - VARIETY CLASSIFICATION")
    print("="*40)
    convnext_model = create_transfer_model("convnext_tiny", NUM_CLASSES)
    convnext_history = train_transfer_model(
        convnext_model, "ConvNeXt-Tiny", train_loader, val_loader,
        EPOCHS, LEARNING_RATE, DEVICE, "Variety Classification"
    )

    # Plot training history
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 2, 1)
    plt.plot(convnext_history['train_acc'], label='Train', marker='o')
    plt.plot(convnext_history['val_acc'], label='Validation', marker='s')
    plt.title('ConvNeXt-Tiny - Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(alpha=0.3)

    plt.subplot(1, 2, 2)
    plt.plot(convnext_history['train_loss'], label='Train', marker='o')
    plt.plot(convnext_history['val_loss'], label='Validation', marker='s')
    plt.title('ConvNeXt-Tiny - Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # ConvNeXt-Tiny Evaluation
    convnext_results = evaluate_transfer_model(
        convnext_model, "ConvNeXt-Tiny", test_loader, class_names, DEVICE, "Variety Classification"
    )

    # Save model info
    model_info = {
        'model': 'ConvNeXt-Tiny',
        'classes': class_names,
        'accuracy': convnext_results['accuracy'],
        'f1_score': convnext_results['f1_macro']
    }
    with open('convnext_model.pkl', 'wb') as f:
        pickle.dump(model_info, f)